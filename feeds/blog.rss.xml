<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Sitespect Documentation</title><link>/</link><description></description><lastBuildDate>Wed, 05 Oct 2016 00:00:00 +0100</lastBuildDate><item><title>Counting users into an experiment</title><link>/2016/counting-users-into-an-experiment</link><description>&lt;p&gt;This post assumes you've got some familiarity with SiteSpect already. What I'll be covering are the key concepts of "counting" users into a test so you can better control when you're counting people into an experiment.&lt;/p&gt;
&lt;h2&gt;A simple example of "counted"&lt;/h2&gt;
&lt;p&gt;Let's start with a simple example test.&lt;/p&gt;
&lt;p&gt;We want to create a test where we want to change the button text on the homepage.&lt;/p&gt;
&lt;p&gt;&lt;img alt="homepage control" src="/img/homepage-control.png" /&gt;&lt;/p&gt;
&lt;p&gt;We want to change "Get times &amp;amp; tickets" to read "Search" instead.&lt;/p&gt;
&lt;p&gt;So far, so simple. You create a factor where:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Trigger:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;URL: Regex to match the homepage URL&lt;/li&gt;
&lt;li&gt;Body: Regex to match "Get times &amp;amp; tickets"&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Variation:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Search: Regex to match "Get times &amp;amp; tickets"&lt;/li&gt;
&lt;li&gt;Replace: Replacement button text&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now before you pat yourself on the back and do your mental high fives (I always do those, they're cool), have a look at the factor you just created and open the "Advanced Settings" accordion:&lt;/p&gt;
&lt;p&gt;&lt;img alt="advanced tab" src="/img/advanced-tab-counted.png" /&gt;&lt;/p&gt;
&lt;p&gt;Pay attention to the "Count user when triggered". &lt;/p&gt;
&lt;p&gt;On a factor, this is defaulted to "Yes", while on a metric, this is defaulted to "No". &lt;/p&gt;
&lt;h3&gt;What does all this mean?&lt;/h3&gt;
&lt;p&gt;When a user triggers your factor, that user will be "counted into" your test. That means they will fall into the test and they will be measured by all your metrics you set up in your campaign.&lt;/p&gt;
&lt;p&gt;For any test, it's important that we count a user at the right point. We want to ensure that &lt;strong&gt;only users who see our change should be counted into the test&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Or specifically, &lt;strong&gt;only users who match the trigger of our factor&lt;/strong&gt; will be counted into our test.&lt;/p&gt;
&lt;p&gt;For this example, we don't need to do anything else. When a user triggers the factor, the user will be counted into the test. &lt;/p&gt;
&lt;p&gt;This is all easy. Everybody on the homepage will fall into this test because everybody will see the button.&lt;/p&gt;
&lt;p&gt;Let's look at a slightly more complex test.&lt;/p&gt;
&lt;h2&gt;A slightly more complicated example&lt;/h2&gt;
&lt;p&gt;Our next test is on the &lt;strong&gt;delivery options&lt;/strong&gt; page.&lt;/p&gt;
&lt;p&gt;&lt;img alt="delivery options page" src="/img/delivery-options-mobile.png" /&gt;&lt;/p&gt;
&lt;p&gt;For this test we want to change the title for the mobile tickets delivery method:&lt;/p&gt;
&lt;p&gt;Replace...
"Skip queues with our mobile app"&lt;/p&gt;
&lt;p&gt;With...
"Skip queues with our mobile app (Free!)"&lt;/p&gt;
&lt;p&gt;We do the same as with our previous test. We create a factor where:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Trigger:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;URL: Your regex to match the delivery options URL&lt;/li&gt;
&lt;li&gt;Body: Your regex to match title text&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Variation:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Search: Regex for the title text&lt;/li&gt;
&lt;li&gt;Replace: Your replacement title text&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So a user is triggered and therefore &lt;strong&gt;counted&lt;/strong&gt; into the test when the &lt;strong&gt;trigger&lt;/strong&gt; qualifies them.&lt;/p&gt;
&lt;p&gt;The set up is the same as before. So what's different? &lt;/p&gt;
&lt;p&gt;Well, not all users will see the mobile ticket option. Users who don't see the mobile tickets option will &lt;strong&gt;not&lt;/strong&gt; be match the trigger and therefore will &lt;strong&gt;not&lt;/strong&gt; be counted.&lt;/p&gt;
&lt;p&gt;So basically, our &lt;strong&gt;counted&lt;/strong&gt; group is &lt;strong&gt;not&lt;/strong&gt; all users who hit the delivery options page, but instead &lt;strong&gt;only those users who match the trigger criteria&lt;/strong&gt;. i.e. Those who will see mobile tickets as a delivery option.&lt;/p&gt;
&lt;p&gt;This wasn't so bad. It was a more complex example but we didn't need to do anything different. &lt;/p&gt;
&lt;p&gt;The default settings for the "Count user" on the factor took care of everything for us. We just needed to understand what it was doing and why.&lt;/p&gt;
&lt;p&gt;Now let's look at an even more complicated example.&lt;/p&gt;
&lt;p&gt;You ready?&lt;/p&gt;
&lt;h2&gt;An even more complicated example test&lt;/h2&gt;
&lt;p&gt;Our next test idea is this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="homepage groupsave" src="/img/homepage-groupsave.png" /&gt;&lt;/p&gt;
&lt;p&gt;Our requirement for this test is the following:&lt;/p&gt;
&lt;p&gt;If a user makes a search for 3 or more passengers, automatically select groupsave AND display the message on the right.&lt;/p&gt;
&lt;p&gt;You got that? Pause for a moment and make sure it's clear.&lt;/p&gt;
&lt;p&gt;We need to do all of this with javacript, so we create a factor with the following setup:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Trigger:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;URL: Your regex to match the homepage URL&lt;/li&gt;
&lt;li&gt;Body: Your regex to match the homepage script block&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Variation:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Search: Regex to find the homepage script block&lt;/li&gt;
&lt;li&gt;Replace: Add your great javascript to do everything the test requires&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You see the problem here?&lt;/p&gt;
&lt;p&gt;ALL traffic is going to be triggered into the test because the experiment conditions are met on the client-side.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Our test group should only be those users who have made a search for three or more passengers&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;This is the only group who are going to see anything different. Everyone else will see the normal experience and will not be subject to anything in our test. So we don't want them counted into our test. They're just noise.&lt;/p&gt;
&lt;p&gt;Ask your local analytics person about this, and they will tell you it'd make their lives better if you could only capture the test group for them. &lt;/p&gt;
&lt;p&gt;So what do you do?&lt;/p&gt;
&lt;p&gt;Well there's two things, you need to do:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Disable the count in the factor&lt;/li&gt;
&lt;li&gt;Count users into the test using javascript&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;1. Disable the count in the factor&lt;/h3&gt;
&lt;p&gt;The concept is simple. We disable count on the factor(s) involved in the test. Great! That's easy. Remember the screenshot I already showed you of where you do that? Here it is again.&lt;/p&gt;
&lt;p&gt;&lt;img alt="advanced tab" src="/img/advanced-tab-counted.png" /&gt;&lt;/p&gt;
&lt;p&gt;You want to set that to "no" and save it.&lt;/p&gt;
&lt;p&gt;Now anyone who triggers the factor will &lt;strong&gt;not&lt;/strong&gt; be counted. &lt;/p&gt;
&lt;p&gt;The next step is to count someone in via JavaScript. That isn't as difficult as it sounds.&lt;/p&gt;
&lt;h3&gt;2. Count users into the test using javascript&lt;/h3&gt;
&lt;p&gt;You should already know how to fire an Event Track metric for SiteSpect to track, but in case you need a refresher:&lt;/p&gt;
&lt;p&gt;Firstly, use the following script to fire an event:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if(window.SS){SS.EventTrack.rp(&amp;#39;SomeValue&amp;#39;);}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Use that script any way you please, like attach it to a button click event. Replace 'SomeValue' with something specific to your use case.&lt;/p&gt;
&lt;p&gt;For our example, we want to fire an event if a user adds three or more passengers from the dropdown.&lt;/p&gt;
&lt;p&gt;Our javascript looks something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if (number_of_passengers &amp;gt; 2){
   if(window.SS){SS.EventTrack.rp(&amp;#39;SomeValue&amp;#39;);}
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Obviously, this is a simplistic example of the script. It's there for demonstration purposes only!&lt;/p&gt;
&lt;p&gt;If everything is working as it should, then you should see a request being made when this event fires. Check the network tab of your fave browser to see it being fired. &lt;/p&gt;
&lt;p&gt;For the above example, you'll see something like this...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/__ssobj/track?event=SomeValue&amp;amp;value=undefined&amp;amp;x=1477109639617-1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So now your script is firing an event. &lt;/p&gt;
&lt;p&gt;You should know that it's useless without a metric to &lt;strong&gt;catch&lt;/strong&gt; the event. Your metric for this will have the following triggers:&lt;/p&gt;
&lt;p&gt;&lt;img alt="metric event track" src="/img/ss-metric-event.png" /&gt;&lt;/p&gt;
&lt;p&gt;Now, if you want to &lt;strong&gt;count&lt;/strong&gt; someone using that metric, just open the same Advance settings that exist for the factor. &lt;/p&gt;
&lt;p&gt;&lt;img alt="advanced tab" src="/img/advanced-tab-counted.png" /&gt;&lt;/p&gt;
&lt;p&gt;And set that to "yes".&lt;/p&gt;
&lt;p&gt;There you have it. You've disabled the count on the factor and you've enabled a count on a metric! Easy, right?&lt;/p&gt;
&lt;h3&gt;Rules and regulations&lt;/h3&gt;
&lt;p&gt;Quick note about being 100% transparent when you're doing things like this. Otherwise it can get confusing for you when it comes to re-using factors and metrics.&lt;/p&gt;
&lt;h4&gt;1. Naming convention&lt;/h4&gt;
&lt;p&gt;When you set a factor to NOT COUNT, append "[NOT COUNTED]" to the end of the name of that factor.&lt;/p&gt;
&lt;p&gt;When you set a metric to COUNT, append "[COUNTED]" to the end of the name of that metric.&lt;/p&gt;
&lt;p&gt;This way, when you review your test build it's obvious that you've made some fundamental changes to how things have been set up.&lt;/p&gt;
&lt;p&gt;These are pretty major changes, so you want to be as transparent about it as possible!&lt;/p&gt;
&lt;h4&gt;2. Put your event-fire javascripts inside a Campaign Variation&lt;/h4&gt;
&lt;p&gt;You want your javascript event track to fire for both the variation AND the control.&lt;/p&gt;
&lt;p&gt;So put your event-fire javascripts into a campaign variation. That way it's available to all the variations in that campaign, including your control.&lt;/p&gt;
&lt;p&gt;The script will also fire in the same way for all variations, so you can better compare behaviour in your sample groups.&lt;/p&gt;
&lt;h4&gt;3. Fire an event to DTM to let Adobe know when you've triggered someone into a test&lt;/h4&gt;
&lt;p&gt;Don't leave Adobe out in the cold! We need to let Adobe know when you're triggering someone into a test using javascript. I've already created a function to do much of the work, so all you need to do is send the function the campaign and variation group ID to add.&lt;/p&gt;
&lt;p&gt;Do this with the following script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="nt"&gt;assign_to_adobe&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;__SS_LISTCAMPAIGN{__SS_TCID__:__SS_VGID__}{;}__&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you add this to your campaign variation, SiteSpect will automatically add the Campaign ID and Variation Group ID to the script. &lt;/p&gt;
&lt;p&gt;So for our example, the final script in our campaign variation is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;number_of_passengers&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="n"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;SS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EventTrack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SomeValue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);}&lt;/span&gt;
   &lt;span class="nt"&gt;assign_to_adobe&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;__SS_LISTCAMPAIGN{__SS_TCID__:__SS_VGID__}{;}__&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We're using DTM, and have a custom event set up to look out for an event like that. The ID's are sent over to DTM, which then attaches the details to an Adobe list variable.&lt;/p&gt;
&lt;p&gt;Now Adobe and SiteSpect should be working in perfect harmony together!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Iqbal Ali</dc:creator><pubDate>Wed, 05 Oct 2016 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:,2016-10-05:2016/counting-users-into-an-experiment</guid><category>traffic-assignment</category><category>test-build</category><category>counting</category></item><item><title>Previewing multiple campaign variations</title><link>/2016/preview-multiple-campaigns</link><description>&lt;p&gt;This post will describe how to preview a multiple campaign variations. So you can check what the combination of tests looks like.&lt;/p&gt;
&lt;h2&gt;What you need to get started&lt;/h2&gt;
&lt;p&gt;First of all you need to install the necessary plugins for your browser.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/modify-headers-for-google/innpjfdalfhpcoinfnehdnbkglpmogdi?hl=en-US"&gt;Modify Header for Google Chrome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://addons.mozilla.org/en-us/firefox/addon/modify-headers/"&gt;Modify Header for Firefox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Add a section as per the image below. &lt;/p&gt;
&lt;p&gt;&lt;img alt="modify headers setting" src="/img/modify-headers-settings.png" /&gt;&lt;/p&gt;
&lt;h3&gt;1. ACTION&lt;/h3&gt;
&lt;p&gt;Add&lt;/p&gt;
&lt;h3&gt;2. NAME:&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; X-SiteSpect-Preview
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;3. VALUE EXAMPLE:&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; { &amp;quot;VG_IDs&amp;quot;: [ &amp;quot;101&amp;quot;, &amp;quot;121&amp;quot; ] }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(this places the user into a preview session that includes variation groups 101 and 121)&lt;/p&gt;
&lt;p&gt;I'm assuming you know where the campaign Variation Group ID's can be found. Note: Campaign ID's are NOT needed since the campaign variation group ID's are unique.&lt;/p&gt;
&lt;h3&gt;4. DESCRIPTION&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Multiple Preview
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;5. TURN IT ON!&lt;/h3&gt;
&lt;p&gt;Hit the green play button on the top of the screen to turn on the header.&lt;/p&gt;
&lt;p&gt;&lt;img alt="modify headers setting" src="/img/modify-headers-settings-switch.png" /&gt;&lt;/p&gt;
&lt;p&gt;And also hit the "on" icon on the row to "activate" the header modifier.&lt;/p&gt;
&lt;p&gt;&lt;img alt="modify headers setting" src="/img/modify-headers-settings-on-off-toggle.png" /&gt;&lt;/p&gt;
&lt;h3&gt;6. PREVIEW&lt;/h3&gt;
&lt;p&gt;You'll need to then use a preview link for all of this to take effect. The preview link is simply this:&lt;/p&gt;
&lt;p&gt;http://www.domain.com/?SS_PREVIEW_EXP=2013_NOV_30_1300GMT (the value is a date that needs to be a future date)&lt;/p&gt;
&lt;p&gt;So for Trainline, a preview link is this:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.thetrainline.com/?SS_PREVIEW_EXP=2090_NOV_30_1300GMT]"&gt;https://www.thetrainline.com/?SS_PREVIEW_EXP=2090_NOV_30_1300GMT&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Iqbal Ali</dc:creator><pubDate>Wed, 05 Oct 2016 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:,2016-10-05:2016/preview-multiple-campaigns</guid><category>previews</category><category>qa</category></item><item><title>The power of the hypothesis in A/B testing</title><link>/2016/the-power-of-the-hypothesis-in-ab-testing</link><description>&lt;p&gt;When it comes to A/B testing, we've found the hypothesis to be an essential part of our process. It works by helping us keep focus on the reason we're testing. It's basically the heart that powers an idea through to completion. &lt;/p&gt;
&lt;p&gt;But what is it about this statement that makes it so invaluable? And how specifically has it helped us? &lt;/p&gt;
&lt;p&gt;Before I answer these questions, let's look at an example hypothesis:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"On the product listings page, presenting users with more information about each product will improve clarity and confidence, therefore increasing overall conversion."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This statement does a number of things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It tells us what we want to change (and the page we want to apply the change to)&lt;/li&gt;
&lt;li&gt;That two variables are related, namely the displaying of product information and the conversion rate&lt;/li&gt;
&lt;li&gt;How and why we think there is a relationship between the two variables&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We now want to create an experiment to prove this hypothesis.&lt;/p&gt;
&lt;p&gt;Before going any further, I have to point out that the hypothesis above was created for the sole purpose of this article. I'll be referring to it throughout the rest of the post.&lt;/p&gt;
&lt;h2&gt;How the hypothesis validates itself&lt;/h2&gt;
&lt;p&gt;With any hypothesis, it's essential that we interrogate it properly, cross-referencing it with as many other sources of information as possible. This includes looking at past tests, any user feedback we've received, as well as any supporting data from our analytics package. We're looking for clues that suggest the assumptions might be true.&lt;/p&gt;
&lt;p&gt;We note that the test idea centres "on the product listings page". This means we'll want to know what the drop-off rate for this page is, as well as the traffic volume -- the more traffic a given page has, the better as it means a test will stand a better chance of reaching statistical significance. &lt;/p&gt;
&lt;p&gt;We also note that we've justified the relationship between our two variables (remember the two variables are: viewing product details and the conversion rate). This relationship is suggested with the "...will improve clarity and confidence..." part of the statement. &lt;/p&gt;
&lt;p&gt;Justifying how the two variables are related helps us "buy" the statement. Without that justification, it might be difficult to see how and why such a relationship could exist. It would feel too much like of a leap in logic. &lt;/p&gt;
&lt;h2&gt;The hypothesis keeps our focus&lt;/h2&gt;
&lt;p&gt;The greatest strength of the hypothesis is it's ability to keep us focused. &lt;/p&gt;
&lt;p&gt;When prioritising our backlog of tests, the hypothesis keeps conversations relevant, to the point, and specific to the assumptions being made. &lt;/p&gt;
&lt;p&gt;It also allows us to check other ideas that might be similar! We can then either combine those tests into one, or just plan a test launch order for them (perhaps starting with the simplest test that will give us some validation).&lt;/p&gt;
&lt;p&gt;When going through the design stages, there is a risk for the scope of the test to balloon. Maybe we get tempted to change more than initially intended, especially when we research other sites and the cool ways they tackle the design challenges.&lt;/p&gt;
&lt;p&gt;To stop us from becoming too ambitious with the solution to our problem, we often find the need to take a step back and lean on our hypothesis again.&lt;/p&gt;
&lt;p&gt;This involves looking at what we're trying to prove and ensuring we've not lost our way. &lt;/p&gt;
&lt;p&gt;For a hypothesis that hasn't proven itself before, we may decide to do the least amount of work in order to prove or disprove it.&lt;/p&gt;
&lt;p&gt;Alternatively, for a hypothesis that &lt;em&gt;has&lt;/em&gt; proven itself, we may decide it’s okay to be a little more ambitious. Either way, it’s a decision we can only be make after referring back to that core statement of ours.&lt;/p&gt;
&lt;h2&gt;Ensuring our test can answer the question we're asking&lt;/h2&gt;
&lt;p&gt;We need to ensure that anything we build is designed in such a way that it answers the questions raised by our hypothesis.&lt;/p&gt;
&lt;p&gt;This may mean deciding on how many variations we’re going to need. For example, if we've made a number of changes, are we controlling for them?&lt;/p&gt;
&lt;p&gt;It often helps check for the possible outcomes we might face, and then ensure we'll have a good chance of understanding why certain results happened. Remember, our hypothesis is that users seeing the product details will end up converting in higher numbers. We need to ensure we can prove this relationship! &lt;/p&gt;
&lt;p&gt;Let’s remind ourselves of the hypothesis again...&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"On the product listings page, presenting users with more information about each product will improve clarity and confidence, therefore increasing overall conversion."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;...and focus on the part of the sentence: "presenting users with more information about each product ... increasing overall conversion". As stated previously, these are the two variables that we think are related, so we definitely know we want to try and measure those two at least!&lt;/p&gt;
&lt;p&gt;Imagine that the final implementation of our test involves an accordion, sliding down to reveal the extra information. Clicking on the accordion will show or hide that information. That means we'll need to track clicks to the expand/collapse component as it's the closest we have to proving that a user has seen the details.&lt;/p&gt;
&lt;p&gt;It also goes without saying that we'll also want to track our overall conversion rate!&lt;/p&gt;
&lt;h2&gt;Checking if the hypothesis is validated&lt;/h2&gt;
&lt;p&gt;If all has gone well, weeks later, we should have a concluded test to analyse. Much time may have elapsed since the formation of that idea, so the hypothesis will act as a reference point for the analyst so that she knows what she’s looking for during analysis.&lt;/p&gt;
&lt;p&gt;These are the possible outcomes of the test:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hypothesis validated (Win!)&lt;/li&gt;
&lt;li&gt;Hypothesis invalidated (Lose!)&lt;/li&gt;
&lt;li&gt;Hypothesis inconclusive (Not sure!)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the test is successful, we may have uncovered an area to concentrate on for future tests. We can therefore create new hypotheses to investigate things further. &lt;/p&gt;
&lt;p&gt;For an unsuccessful or inconclusive test, we may still find we've learned something. So it's not all bad! Perhaps we proved that there may not be a relationship between our two variables after all. Or maybe we’ve uncovered a new friction point. Like inconsistent messaging or something, meaning we might want to revise the test conditions and try again.&lt;/p&gt;
&lt;p&gt;Either way, win or lose, the findings of this test should lead to more hypotheses, and this will in turn deliver us with a new set of test statements to validate.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Iqbal Ali</dc:creator><pubDate>Wed, 05 Oct 2016 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:,2016-10-05:2016/the-power-of-the-hypothesis-in-ab-testing</guid><category>optimisation</category></item></channel></rss>